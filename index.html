<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Sri Aditya Deevi </title> <meta name="author" content="Sri Aditya Deevi"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://dsriaditya999.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/awards/">awards </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/certifications/">certifications </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/SriAdityaDeevi_Resume_30Jun2024.pdf" target="_blank" rel="noopener noreferrer">cv <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Sri Aditya</span> Deevi </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic_sriadi_enhanced-480.webp 480w,/assets/img/prof_pic_sriadi_enhanced-800.webp 800w,/assets/img/prof_pic_sriadi_enhanced-1400.webp 1400w," sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic_sriadi_enhanced.png?33e387bcd995ed790a526f0cb096ccd2" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic_sriadi_enhanced.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <center> U R Rao Satellite Centre</center> <center>Bengaluru, Karnataka</center> </div> </div> <div class="clearfix"> <p>I am a Scientist in the Mission Simulation Group (MSG) at <a href="https://www.ursc.gov.in" rel="external nofollow noopener" target="_blank">U.R. Rao Satellite Centre, Indian Space Research Organization (ISRO)</a>. My work involves tackling diverse AI and robotics research challenges in aerospace systems. Currently, I am engaged in several notable projects, including pose estimation and tracking in uncooperative spacecraft rendezvous operations using monocular data, estimating the relative pose of space resident objects with LIDAR point cloud data, developing autonomous navigation algorithms for rovers, and creating vision-based solutions for the autonomous landing of unmanned aerial vehicles (UAVs).</p> <p>Before joining ISRO, I graduated from <a href="https://www.caltech.edu" rel="external nofollow noopener" target="_blank">Caltech</a> with a Masters degree in Electrical Engineering, having earned the prestigious and fully funded Dr. Satish Dhawan Fellowship from the Department of Space, Government of India. At Caltech, I conducted research to develop efficacious multimodal deep sensor fusion methods for object detection in the <a href="http://aerospacerobotics.caltech.edu" rel="external nofollow noopener" target="_blank">Autonomous Robotics and Control Lab (ARCL)</a> led by Prof. <a href="https://scholar.google.com/citations?user=-ClLU3EAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Soon-Jo Chung</a>. Following my time at Caltech, I had the opportunity to intern at the <a href="https://www.jpl.nasa.gov" rel="external nofollow noopener" target="_blank">Jet Propulsion Laboratory (JPL)</a> in the Optical Communication Systems group. There, I collaborated with Dr. Sabino Piazzolla and spearheaded the development of short-term forecasting techniques to predict key atmospheric parameters helpful in characterizing the optical channel.</p> <p>In a more general sense, I am interested in Machine Learning, Robotics and Computer Vision. I am particularly fascinated by the intersection of these fields and their applications in aerospace systems. I am always on the lookout for exciting research opportunities and collaborations, so feel free to reach out if you have any ideas or projects in mind.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Apr 04, 2024</th> <td> Joined <a href="https://www.ursc.gov.in" rel="external nofollow noopener" target="_blank">U.R. Rao Satellite Centre</a> as a Scientist/Engineer - ‘SC’ in the Mission Simulation Group. </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 29, 2024</th> <td> Presented our paper, <a href="https://openaccess.thecvf.com/content/WACV2024/html/Deevi_RGB-X_Object_Detection_via_Scene-Specific_Fusion_Modules_WACV_2024_paper.html" rel="external nofollow noopener" target="_blank">RGB-X Object Detection via Scene-Specific Fusion Modules</a>, in the <a href="https://superagi.com/agi-leap-summit/" rel="external nofollow noopener" target="_blank">AGI Leap Summit</a> organized by <a href="https://superagi.com" rel="external nofollow noopener" target="_blank">SuperAGI</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 10, 2024</th> <td> Our <a href="https://openaccess.thecvf.com/content/WACV2024/html/Deevi_RGB-X_Object_Detection_via_Scene-Specific_Fusion_Modules_WACV_2024_paper.html" rel="external nofollow noopener" target="_blank">paper</a> published in the Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 20, 2023</th> <td> Completed Graduate Research Internship at <a href="https://www.jpl.nasa.gov" rel="external nofollow noopener" target="_blank">NASA’s Jet Propulsion Laboratory</a>. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/rgb-x-object-detection-480.webp 480w,/assets/img/publication_preview/rgb-x-object-detection-800.webp 800w,/assets/img/publication_preview/rgb-x-object-detection-1400.webp 1400w," sizes="500px" type="image/webp"> <img src="/assets/img/publication_preview/rgb-x-object-detection.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="rgb-x-object-detection.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Deevi_2024_WACV" class="col-sm-8"> <div class="title">RGB-X Object Detection via Scene-Specific Fusion Modules</div> <div class="author"> <em>Sri Aditya Deevi</em>, Connor Lee, <a href="https://scholar.google.com/citations?hl=en&amp;user=mVY8wE8AAAAJ" rel="external nofollow noopener" target="_blank">Lu Gan</a> , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Sushruth Nagesh, Gaurav Pandey, Soon-Jo Chung' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em>, Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openaccess.thecvf.com/content/WACV2024/html/Deevi_RGB-X_Object_Detection_via_Scene-Specific_Fusion_Modules_WACV_2024_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/dsriaditya999/RGBXFusion" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/RGB_X_Object_Detection_via_Scene_Specific_Fusion_Modules__Poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> <a href="/assets/pdf/wacv_rgbx_video.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="abstract hidden"> <p>Multimodal deep sensor fusion has the potential to enable autonomous vehicles to visually understand their surrounding environments in all weather conditions. However, existing deep sensor fusion methods usually employ convoluted architectures with intermingled multimodal features, requiring large coregistered multimodal datasets for training. In this work, we present an efficient and modular RGB-X fusion network that can leverage and fuse pretrained single-modal models via scene-specific fusion modules, thereby enabling joint input-adaptive network architectures to be created using small, coregistered multimodal datasets. Our experiments demonstrate the superiority of our method compared to existing works on RGB-thermal and RGB-gated datasets, performing fusion using only a small amount of additional parameters. Our code is available at https://github.com/dsriaditya999/RGBXFusion.</p> </div> </div> </div> </li></ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%64%73%72%69%61%64%69%74%79%61%39%39%39@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="/assets/pdf/SriAdityaDeevi_Resume_30Jun2024.pdf" target="_blank" rel="noopener noreferrer" title="CV"><i class="ai ai-cv"></i></a> <a href="https://scholar.google.com/citations?user=6XKjIWUAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/dsriaditya999" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/sri-aditya-deevi" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> </div> <div class="contact-note">The best way to reach me is by email at dsriaditya999 [at] gmail [dot] com. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Sri Aditya Deevi. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-awards",title:"awards",description:"",section:"Navigation",handler:()=>{window.location.href="/awards/"}},{id:"nav-publications",title:"publications",description:"Publications in reversed chronological order",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-certifications",title:"certifications",description:"",section:"Navigation",handler:()=>{window.location.href="/certifications/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-github-metadata",title:"a post with github metadata",description:"a quick run down on accessing github metadata.",section:"Posts",handler:()=>{window.location.href="/blog/2020/github-metadata/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-joined-lt-a-href-quot-https-www-ursc-gov-in-quot-gt-u-r-rao-satellite-centre-lt-a-gt-as-a-scientist-engineer-sc-in-the-mission-simulation-group",title:"Joined &lt;a href=&quot;https://www.ursc.gov.in&quot;&gt;U.R. Rao Satellite Centre&lt;/a&gt; as a Scientist/Engineer - \u2018SC\u2019 in the Mission Simulation Group.",description:"",section:"News"},{id:"news-presented-our-paper-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2024-html-deevi-rgb-x-object-detection-via-scene-specific-fusion-modules-wacv-2024-paper-html-quot-gt-rgb-x-object-detection-via-scene-specific-fusion-modules-lt-a-gt-in-the-lt-a-href-quot-https-superagi-com-agi-leap-summit-quot-gt-agi-leap-summit-lt-a-gt-organized-by-lt-a-href-quot-https-superagi-com-quot-gt-superagi-lt-a-gt",title:"Presented our paper, &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2024/html/Deevi_RGB-X_Object_Detection_via_Scene-Specific_Fusion_Modules_WACV_2024_paper.html&quot;&gt;RGB-X Object Detection via Scene-Specific Fusion Modules&lt;/a&gt;, in the &lt;a href=&quot;https://superagi.com/agi-leap-summit/&quot;&gt;AGI Leap Summit&lt;/a&gt; organized by &lt;a href=&quot;https://superagi.com&quot;&gt;SuperAGI&lt;/a&gt;.",description:"",section:"News"},{id:"news-our-lt-a-href-quot-https-openaccess-thecvf-com-content-wacv2024-html-deevi-rgb-x-object-detection-via-scene-specific-fusion-modules-wacv-2024-paper-html-quot-gt-paper-lt-a-gt-published-in-the-proceedings-of-the-ieee-cvf-winter-conference-on-applications-of-computer-vision-wacv-2024",title:"Our &lt;a href=&quot;https://openaccess.thecvf.com/content/WACV2024/html/Deevi_RGB-X_Object_Detection_via_Scene-Specific_Fusion_Modules_WACV_2024_paper.html&quot;&gt;paper&lt;/a&gt; published in the Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024.",description:"",section:"News"},{id:"news-completed-graduate-research-internship-at-lt-a-href-quot-https-www-jpl-nasa-gov-quot-gt-nasa-s-jet-propulsion-laboratory-lt-a-gt",title:"Completed Graduate Research Internship at &lt;a href=&quot;https://www.jpl.nasa.gov&quot;&gt;NASA\u2019s Jet Propulsion Laboratory&lt;/a&gt;.",description:"",section:"News"},{id:"projects-self-untangling-robotic-snake-arm-with-dynamic-obstacle-avoidance",title:"Self Untangling Robotic Snake Arm with Dynamic Obstacle Avoidance",description:"",section:"Projects",handler:()=>{window.location.href="/projects/0_project/"}},{id:"projects-iot-controlled-smart-home",title:"IoT controlled Smart Home",description:"Voice-activated lighting automation using Google Assistant and Internet of Things",section:"Projects",handler:()=>{window.location.href="/projects/10_project/"}},{id:"projects-voice-controlled-robot",title:"Voice Controlled Robot",description:"Voice-activated robot navigation using mobile phone commands and Bluetooth technology",section:"Projects",handler:()=>{window.location.href="/projects/11_project/"}},{id:"projects-fiscal-responsibility-index",title:"Fiscal Responsibility Index",description:"Quantifying government fiscal discipline using economic data and advanced modeling",section:"Projects",handler:()=>{window.location.href="/projects/12_project/"}},{id:"projects-fire-alarm",title:"Fire Alarm",description:"Fire alarm system with intensity indication using thermistor-based temperature sensing",section:"Projects",handler:()=>{window.location.href="/projects/13_project/"}},{id:"projects-rrt-based-motion-planner-for-non-holonomic-mobile-robots",title:"RRT Based Motion Planner for Non-Holonomic Mobile Robots",description:"",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-non-holonomic-rrt-with-dynamic-replanning-and-obstacle-mapping",title:"Non Holonomic RRT with Dynamic Replanning and Obstacle Mapping",description:"",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-atmospheric-parameter-forecasting-for-optical-channel-characterization",title:"Atmospheric Parameter Forecasting for Optical Channel Characterization",description:"",section:"Projects",handler:()=>{window.location.href="/projects/2_project_1/"}},{id:"projects-rgb-x-object-detection-via-scene-specific-fusion-modules",title:"RGB-X Object Detection via Scene-Specific Fusion Modules",description:"Enhancing Autonomous Vehicle vision with adpative multimodal fusion for all-weather object detection",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-autonomous-robotic-grasping",title:"Autonomous Robotic Grasping",description:"Exploring vision-based robotic grasping for effective object manipulation in static and dynamic environments.",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-efficient-self-supervised-neural-architecture-search",title:"Efficient Self-Supervised Neural Architecture Search",description:"Crafting deep learning architectures efficiently with self-supervised neural architecture search",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-pose-estimation-for-autonomous-robotic-grasping",title:"Pose Estimation for Autonomous Robotic Grasping",description:"Efficient and effective 6D pose estimation of objects using single RGB images",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-scene-text-recognition",title:"Scene Text Recognition",description:"Recognizing Text in Ubiquitous Scenes",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-automatic-speaker-recognition-system",title:"Automatic Speaker Recognition System",description:"Recognizing Speakers using Mel Frequency Cepstral Coefficients and Vector Quantization",section:"Projects",handler:()=>{window.location.href="/projects/7_project_1/"}},{id:"projects-swadeshi-microprocessor-challenge",title:"Swadeshi Microprocessor Challenge",description:"An FMCW Radar Module for Driving Assistance",section:"Projects",handler:()=>{window.location.href="/projects/7_project_2/"}},{id:"projects-anomaly-detection-in-satellite-telemetry",title:"Anomaly Detection in Satellite Telemetry",description:"",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-ecg-beat-classification",title:"ECG Beat Classification",description:"ECG analysis with a deep learning approach for efficient denoising and beat-wise classification, enhancing cardiovascular diagnostics",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%64%73%72%69%61%64%69%74%79%61%39%39%39@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=6XKjIWUAAAAJ","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/dsriaditya999","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/sri-aditya-deevi","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </body> </html>